#!/usr/bin/env python3
"""Export function names and data labels from Binary Ninja via its HTTP API.

Connects to the BN MCP HTTP server, paginates through all functions and
data items, filters out auto-generated names, and writes .sym files in
binanana format.

Requires Binary Ninja running with the binary_ninja_mcp plugin active.
"""

import json
import sys
import urllib.request
import urllib.error
from pathlib import Path

# BN auto-generated name prefixes to skip
AUTO_PREFIXES = (
    "sub_",
    "data_",
    "j_",
    "byte_",
    "word_",
    "dword_",
    "qword_",
    "float_",
    "double_",
    "var_",
    "arg_",
)

# Address width by architecture
ADDR_WIDTH = {
    "i386": 8,
    "amd64": 16,
    "arm64": 16,
}

DEFAULT_BN_URL = "http://localhost:9009"

# Use a large limit to fetch everything in one request. BN's
# get_function_names rebuilds the full list on every call, so
# pagination with small pages causes O(pages * total) work.
FETCH_LIMIT = 999999


def fetch_json(url: str, timeout: int = 600) -> dict:
    """Fetch JSON from a URL."""
    req = urllib.request.Request(url)
    with urllib.request.urlopen(req, timeout=timeout) as resp:
        return json.loads(resp.read())


def is_auto_name(name: str) -> bool:
    """Return True if the name is auto-generated by Binary Ninja."""
    for prefix in AUTO_PREFIXES:
        if name.startswith(prefix):
            return True
    return False


def sanitize_name(name: str) -> str | None:
    """Replace spaces with underscores in symbol names.

    Returns None if the name cannot be sanitized into a valid .sym
    identifier (e.g. empty after sanitization).
    """
    # Replace spaces, commas, and angle bracket padding that BN
    # inserts in C++ template names
    sanitized = name.replace(" ", "_").replace(",", ",")
    # The .sym format is space-delimited; names must not contain spaces
    if not sanitized or " " in sanitized:
        return None
    return sanitized


def format_addr(hex_str: str, width: int) -> str:
    """Convert '0x401000' to zero-padded hex of the given width."""
    addr = int(hex_str, 16)
    return f"{addr:0{width}X}"


def collect_existing_addresses(profile_dir: Path) -> set[str]:
    """Collect all addresses already defined in non-export symbol files."""
    addresses = set()
    symbol_dir = profile_dir / "symbol"
    if not symbol_dir.is_dir():
        return addresses
    for category_dir in symbol_dir.iterdir():
        if not category_dir.is_dir() or category_dir.name == "export":
            continue
        for sym_file in category_dir.glob("*.sym"):
            with open(sym_file) as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith("#") or line.startswith(";"):
                        continue
                    comment_idx = line.find(";")
                    parse_line = line[:comment_idx].strip() if comment_idx >= 0 else line
                    parts = parse_line.split()
                    if len(parts) >= 3:
                        addresses.add(parts[1])
    return addresses


def fetch_all_functions(bn_url: str) -> list[dict]:
    """Fetch all functions from BN in a single request."""
    url = f"{bn_url}/functions?offset=0&limit={FETCH_LIMIT}"
    data = fetch_json(url)
    return data.get("functions", [])


def fetch_all_data(bn_url: str) -> list[dict]:
    """Fetch all data items from BN in a single request."""
    url = f"{bn_url}/data?offset=0&limit={FETCH_LIMIT}&length=0"
    data = fetch_json(url)
    return data.get("data", [])


def main():
    if len(sys.argv) < 2:
        print(f"Usage: {sys.argv[0]} <profile-dir> [--bn-url URL]", file=sys.stderr)
        sys.exit(1)

    profile_dir = Path(sys.argv[1])
    bn_url = DEFAULT_BN_URL

    # Parse optional --bn-url
    args = sys.argv[2:]
    i = 0
    while i < len(args):
        if args[i] == "--bn-url" and i + 1 < len(args):
            bn_url = args[i + 1].rstrip("/")
            i += 2
        else:
            print(f"Unknown argument: {args[i]}", file=sys.stderr)
            sys.exit(1)

    # Read profile info
    info_path = profile_dir / "info.json"
    if not info_path.exists():
        print(f"Error: {info_path} not found", file=sys.stderr)
        sys.exit(1)

    with open(info_path) as f:
        info = json.load(f)

    arch = info.get("arch", "amd64")
    addr_width = ADDR_WIDTH.get(arch, 16)

    print(f"Profile: {profile_dir.name}")
    print(f"Architecture: {arch} ({addr_width}-digit addresses)")
    print(f"BN URL: {bn_url}")

    # Collect addresses already in categorized symbol files
    existing_addrs = collect_existing_addresses(profile_dir)
    if existing_addrs:
        print(f"Existing symbols in other categories: {len(existing_addrs)}")

    # Test connection
    try:
        fetch_json(f"{bn_url}/status")
    except urllib.error.URLError as e:
        print(f"Error: cannot connect to BN at {bn_url}: {e}", file=sys.stderr)
        sys.exit(1)

    # Fetch functions
    print("Fetching functions...", flush=True)
    all_funcs = fetch_all_functions(bn_url)
    print(f"  Total functions in BN: {len(all_funcs)}")

    # Filter auto-generated names and sanitize
    func_addrs = set()
    named_funcs = []
    skipped_funcs = 0
    skipped_existing = 0
    for func in all_funcs:
        name = func.get("name", "")
        if not name or is_auto_name(name):
            continue
        clean = sanitize_name(name)
        if clean is None:
            skipped_funcs += 1
            continue
        addr = format_addr(func["address"], addr_width)
        if addr in existing_addrs:
            skipped_existing += 1
            continue
        func_addrs.add(addr)
        named_funcs.append((clean, addr))

    # Sort by address
    named_funcs.sort(key=lambda f: f[1])
    print(f"  User-named functions: {len(named_funcs)}")
    if skipped_funcs:
        print(f"  Skipped (unsanitizable names): {skipped_funcs}")
    if skipped_existing:
        print(f"  Skipped (already in other categories): {skipped_existing}")

    # Fetch data items
    print("Fetching data items...", flush=True)
    all_data = fetch_all_data(bn_url)
    print(f"  Total data items in BN: {len(all_data)}")

    # Filter unnamed, auto-generated, and duplicate-address data
    named_data = []
    skipped_data = 0
    skipped_dup = 0
    for item in all_data:
        name = item.get("name", "")
        if not name or name == "(unnamed)" or is_auto_name(name):
            continue
        clean = sanitize_name(name)
        if clean is None:
            skipped_data += 1
            continue
        addr = format_addr(item["address"], addr_width)
        # Skip data labels at addresses already in other categories or
        # claimed by functions in this export
        if addr in existing_addrs or addr in func_addrs:
            skipped_dup += 1
            continue
        named_data.append((clean, addr))

    # Sort by address
    named_data.sort(key=lambda d: d[1])
    print(f"  User-named data labels: {len(named_data)}")
    if skipped_data:
        print(f"  Skipped (unsanitizable names): {skipped_data}")
    if skipped_dup:
        print(f"  Skipped (duplicate address with function): {skipped_dup}")

    # Ensure output directory exists
    export_dir = profile_dir / "symbol" / "export"
    export_dir.mkdir(parents=True, exist_ok=True)

    # Write func.sym
    func_path = export_dir / "func.sym"
    with open(func_path, "w") as f:
        for name, addr in named_funcs:
            f.write(f"{name} {addr} f\n")
    print(f"  Wrote {len(named_funcs)} functions to {func_path}")

    # Write label.sym
    label_path = export_dir / "label.sym"
    with open(label_path, "w") as f:
        for name, addr in named_data:
            f.write(f"{name} {addr} l\n")
    print(f"  Wrote {len(named_data)} labels to {label_path}")

    # Count total functions across all categories (existing + export)
    total_funcs = len(named_funcs)
    symbol_dir = profile_dir / "symbol"
    for category_dir in symbol_dir.iterdir():
        if not category_dir.is_dir() or category_dir.name == "export":
            continue
        for sym_file in category_dir.glob("func.sym"):
            with open(sym_file) as fh:
                for line in fh:
                    line = line.strip()
                    if line and not line.startswith("#") and not line.startswith(";"):
                        comment_idx = line.find(";")
                        parse_line = line[:comment_idx].strip() if comment_idx >= 0 else line
                        parts = parse_line.split()
                        if len(parts) >= 3 and parts[2] == "f":
                            total_funcs += 1

    info["function_count"] = total_funcs
    with open(info_path, "w") as f:
        json.dump(info, f, indent=2)
        f.write("\n")
    print(f"  Updated function_count to {total_funcs} in info.json")

    print(f"\nDone. Total symbols exported: {len(named_funcs) + len(named_data)}")


if __name__ == "__main__":
    main()
